# ğŸ“Œ GeliÅŸmiÅŸ Metin MadenciliÄŸi Teknikleri ile Optimum Konu SayÄ±sÄ±nÄ±n AraÅŸtÄ±rÄ±lmasÄ±

Bu proje, **Latent Dirichlet Allocation (LDA) ve BERTopic algoritmalarÄ±nÄ± kullanarak metin madenciliÄŸi ile optimum konu sayÄ±sÄ±nÄ± belirlemeyi amaÃ§lamaktadÄ±r**. Ã‡alÄ±ÅŸma, **bilimsel makalelerin baÅŸlÄ±k ve Ã¶zetlerinden oluÅŸan bir veri kÃ¼mesi Ã¼zerinde** gerÃ§ekleÅŸtirilmiÅŸtir.

## ğŸ“– Proje AÃ§Ä±klamasÄ±

- **Metin verileri iÅŸlenerek ve temizlenerek** konularÄ±n belirlenmesine uygun hale getirilmiÅŸtir.  
- **LDA ve BERTopic algoritmalarÄ± kullanÄ±larak konu modelleme iÅŸlemi** gerÃ§ekleÅŸtirilmiÅŸtir.  
- **KarÄ±ÅŸÄ±klÄ±k (perplexity) ve tutarlÄ±lÄ±k (coherence) metrikleri kullanÄ±larak optimum konu sayÄ±sÄ± belirlenmiÅŸtir.**  
- **LDA ve BERTopic sonuÃ§larÄ± gÃ¶rselleÅŸtirilmiÅŸ ve karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r.**  

## ğŸ“Š KullanÄ±lan Veri KÃ¼mesi

- **8989 satÄ±r ve 3 sÃ¼tun (id, baÅŸlÄ±k, Ã¶zet)** iÃ§eren veri seti kullanÄ±lmÄ±ÅŸtÄ±r.  
- ID sÃ¼tunu kaldÄ±rÄ±larak **baÅŸlÄ±k ve Ã¶zet sÃ¼tunlarÄ± birleÅŸtirilmiÅŸtir.**  
- **Ã–n iÅŸleme adÄ±mlarÄ±:**  
  - Noktalama iÅŸaretlerinin kaldÄ±rÄ±lmasÄ±  
  - Metnin kÃ¼Ã§Ã¼k harfe Ã§evrilmesi  
  - Kelime kÃ¶klerine indirgenmesi (stemming)  
  - Durdurma kelimelerinin Ã§Ä±karÄ±lmasÄ±  

## ğŸ” KullanÄ±lan Konu Modelleme YÃ¶ntemleri

### **1. Latent Dirichlet Allocation (LDA)**
- **OlasÄ±lÄ±klÄ± bir model** olup, her belgeyi bir konu karÄ±ÅŸÄ±mÄ± ve her konuyu kelime daÄŸÄ±lÄ±mÄ± olarak ele alÄ±r.  
- **Optimum konu sayÄ±sÄ±nÄ± belirlemek iÃ§in karÄ±ÅŸÄ±klÄ±k ve tutarlÄ±lÄ±k skorlarÄ± kullanÄ±lmÄ±ÅŸtÄ±r.**  

### **2. BERTopic**
- **Transformer tabanlÄ± bir model olup, kelimelerin baÄŸlamsal anlamÄ±nÄ± kullanarak konularÄ± belirler.**  
- **KonularÄ±n daha ayrÄ±ntÄ±lÄ± ayrÄ±ÅŸtÄ±rÄ±lmasÄ±nÄ± saÄŸlar.**  

## ğŸ† Optimum Konu SayÄ±sÄ± Belirleme SÃ¼reci

**Optimum konu sayÄ±sÄ±nÄ± belirlemek iÃ§in ÅŸu metrikler kullanÄ±lmÄ±ÅŸtÄ±r:**  
- **KarÄ±ÅŸÄ±klÄ±k (Perplexity):** Modelin metin verisini ne kadar iyi tahmin ettiÄŸini gÃ¶sterir.  
- **TutarlÄ±lÄ±k (Coherence):** Konu iÃ§erisindeki kelimelerin anlamsal baÄŸlÄ±lÄ±ÄŸÄ±nÄ± Ã¶lÃ§er:  
  - UCI Coherence  
  - UMass Coherence  
  - CV Coherence  

**Normalizasyon YÃ¶ntemleri:**  
- Min-Max Normalizasyon  
- Ortalama Normalizasyon  
- T-Skor Normalizasyon  

Bu metrikler **lambda deÄŸerleri ile aÄŸÄ±rlÄ±klandÄ±rÄ±larak birleÅŸik skor oluÅŸturulmuÅŸ ve optimum konu sayÄ±sÄ± 16 olarak belirlenmiÅŸtir.**  

## ğŸ“Š Deneysel SonuÃ§lar

- **LDA modeli iÃ§in 16 konulu daÄŸÄ±lÄ±m en iyi sonucu vermiÅŸtir.**  
- **BERTopic, konularÄ± daha iyi ayrÄ±ÅŸtÄ±rÄ±rken, bazÄ± konularÄ±n Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼ gÃ¶zlemlenmiÅŸtir.**  
- **Her iki model iÃ§in konularÄ±n mesafe haritalarÄ± ve anahtar kelimeler analiz edilmiÅŸtir.**  

DetaylÄ± sonuÃ§lar iÃ§in **[ğŸ“„ Proje Raporu](Rapor/Veri MadenciliÄŸi Rapor.pdf)** dosyasÄ±nÄ± inceleyebilirsiniz.

